"""ê¸€ë¡œë²Œ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° â€” RSS ê¸°ë°˜ ì‹¤ì‹œê°„ í—¤ë“œë¼ì¸ ìˆ˜ì§‘.

ì§€ì •í•™ ë¦¬ìŠ¤í¬, ë§¤í¬ë¡œ ì´ë²¤íŠ¸, ì‹œì¥ ê¸‰ë³€ ë‰´ìŠ¤ë¥¼ ìë™ ìˆ˜ì§‘í•˜ì—¬
AI ì»¨í…ìŠ¤íŠ¸ì™€ ë¸Œë¦¬í•‘ì— ë°˜ì˜í•œë‹¤.

v6.0: ì´ˆê¸° ë²„ì „ â€” RSS í”¼ë“œ ê¸°ë°˜
v6.1: ìœ„ê¸° ê°ì§€ + ë§¤í¬ë¡œ ì„ í–‰ì§€í‘œ ì—°ë™ + ì ì‘í˜• ë¹ˆë„
"""
from __future__ import annotations

import asyncio
import logging
import xml.etree.ElementTree as ET
from datetime import datetime
from dataclasses import dataclass, field

from kstock.core.tz import KST

logger = logging.getLogger(__name__)

# â”€â”€ RSS í”¼ë“œ ì†ŒìŠ¤ ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

RSS_FEEDS: list[dict] = [
    # í•œêµ­ ë‰´ìŠ¤
    {
        "name": "í•œê²½ ê¸€ë¡œë²Œ",
        "url": "https://www.hankyung.com/feed/globalmarket",
        "lang": "ko",
        "category": "market",
    },
    {
        "name": "ì—°í•©ë‰´ìŠ¤ ê²½ì œ",
        "url": "https://www.yna.co.kr/rss/economy.xml",
        "lang": "ko",
        "category": "economy",
    },
    {
        "name": "ì—°í•©ë‰´ìŠ¤ êµ­ì œ",
        "url": "https://www.yna.co.kr/rss/international.xml",
        "lang": "ko",
        "category": "geopolitics",
    },
    # ê¸€ë¡œë²Œ ì˜ë¬¸ ë‰´ìŠ¤
    {
        "name": "CNBC World",
        "url": "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=100727362",
        "lang": "en",
        "category": "market",
    },
    {
        "name": "Reuters Business",
        "url": "https://www.reutersagency.com/feed/?taxonomy=best-sectors&post_type=best",
        "lang": "en",
        "category": "market",
    },
]

# â”€â”€ ê¸´ê¸‰ ì´ë²¤íŠ¸ í‚¤ì›Œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

URGENT_KEYWORDS_KO = [
    "ì „ìŸ", "ê³µìŠµ", "í­ê²©", "ë¯¸ì‚¬ì¼", "í•µ", "ì œì¬", "ë´‰ì‡„",
    "ëŒ€ê³µí™©", "ê²½ê¸°ì¹¨ì²´", "ë¦¬ì„¸ì…˜", "ê¸ˆìœµìœ„ê¸°", "ë””í´íŠ¸", "íŒŒì‚°",
    "ê¸‰ë½", "í­ë½", "ì„œí‚·ë¸Œë ˆì´ì»¤", "ë¸”ë™ë¨¼ë°ì´", "íŒ¨ë‹‰",
    "ê¸´ê¸‰", "ê³„ì—„", "ì¿ ë°íƒ€", "í…ŒëŸ¬",
    "ê¸ˆë¦¬ ì¸ìƒ", "ê¸ˆë¦¬ ì¸í•˜", "ì–‘ì ì™„í™”", "ì–‘ì ê¸´ì¶•",
    "ê´€ì„¸", "ë¬´ì—­ì „ìŸ", "ìˆ˜ì¶œê·œì œ",
    "ìœ ê°€ ê¸‰ë“±", "ìœ ê°€ í­ë“±", "í˜¸ë¥´ë¬´ì¦ˆ",
]

URGENT_KEYWORDS_EN = [
    "war", "strike", "bomb", "missile", "nuclear", "sanction", "blockade",
    "recession", "depression", "crisis", "default", "bankrupt",
    "crash", "plunge", "circuit breaker", "panic", "black monday",
    "emergency", "martial law", "coup", "terror",
    "rate hike", "rate cut", "QE", "QT",
    "tariff", "trade war", "export ban",
    "oil surge", "oil spike", "hormuz",
]

# ì‹œì¥ ì˜í–¥ë„ í‚¤ì›Œë“œ (ê°€ì¤‘ì¹˜)
IMPACT_KEYWORDS = {
    "ì „ìŸ": 10, "war": 10, "ê³µìŠµ": 9, "strike": 8,
    "í•µ": 10, "nuclear": 10, "ë¯¸ì‚¬ì¼": 8, "missile": 8,
    "í­ë½": 9, "crash": 9, "ëŒ€ê³µí™©": 10, "depression": 10,
    "ê²½ê¸°ì¹¨ì²´": 8, "recession": 8, "ê¸ˆìœµìœ„ê¸°": 9, "crisis": 9,
    "ì„œí‚·ë¸Œë ˆì´ì»¤": 9, "circuit breaker": 9,
    "ë´‰ì‡„": 8, "blockade": 8, "í˜¸ë¥´ë¬´ì¦ˆ": 9, "hormuz": 9,
    "ë””í´íŠ¸": 9, "default": 8, "íŒŒì‚°": 7, "bankrupt": 7,
    "ê´€ì„¸": 6, "tariff": 6, "ì œì¬": 7, "sanction": 7,
    "ê¸‰ë½": 7, "plunge": 7, "ê¸‰ë“±": 6, "surge": 5,
}


@dataclass
class NewsItem:
    """ë‹¨ì¼ ë‰´ìŠ¤ í—¤ë“œë¼ì¸."""
    title: str
    source: str
    url: str = ""
    published: str = ""
    category: str = ""  # market, geopolitics, economy
    lang: str = "ko"
    impact_score: int = 0  # ì‹œì¥ ì˜í–¥ë„ (0-10)
    is_urgent: bool = False


def _compute_impact(title: str) -> tuple[int, bool]:
    """í—¤ë“œë¼ì¸ì—ì„œ ì‹œì¥ ì˜í–¥ë„ ì ìˆ˜ ê³„ì‚°."""
    title_lower = title.lower()
    max_score = 0
    for kw, score in IMPACT_KEYWORDS.items():
        if kw.lower() in title_lower:
            max_score = max(max_score, score)
    is_urgent = max_score >= 8
    return max_score, is_urgent


def _parse_rss(xml_text: str, feed: dict) -> list[NewsItem]:
    """RSS XML íŒŒì‹± â†’ NewsItem ë¦¬ìŠ¤íŠ¸."""
    items = []
    try:
        root = ET.fromstring(xml_text)
        # RSS 2.0 ë˜ëŠ” Atom
        channel = root.find("channel")
        if channel is not None:
            entries = channel.findall("item")
        else:
            # Atom feed
            ns = {"atom": "http://www.w3.org/2005/Atom"}
            entries = root.findall("atom:entry", ns)
            if not entries:
                entries = root.findall("entry")

        for entry in entries[:10]:
            title = ""
            link = ""
            pub_date = ""

            # RSS 2.0
            t = entry.find("title")
            if t is not None and t.text:
                title = t.text.strip()
            l = entry.find("link")
            if l is not None:
                link = (l.text or l.get("href", "")).strip()
            p = entry.find("pubDate")
            if p is not None and p.text:
                pub_date = p.text.strip()
            # Atom fallback
            if not pub_date:
                p2 = entry.find("published") or entry.find("updated")
                if p2 is not None and p2.text:
                    pub_date = p2.text.strip()

            if not title:
                continue

            impact, urgent = _compute_impact(title)
            items.append(NewsItem(
                title=title,
                source=feed["name"],
                url=link,
                published=pub_date,
                category=feed.get("category", "market"),
                lang=feed.get("lang", "ko"),
                impact_score=impact,
                is_urgent=urgent,
            ))

    except ET.ParseError as e:
        logger.debug("RSS parse error for %s: %s", feed["name"], e)
    except Exception as e:
        logger.debug("RSS processing error for %s: %s", feed["name"], e)

    return items


async def fetch_global_news(
    max_per_feed: int = 5,
    feeds: list[dict] | None = None,
) -> list[NewsItem]:
    """ê¸€ë¡œë²Œ ë‰´ìŠ¤ RSS í”¼ë“œì—ì„œ í—¤ë“œë¼ì¸ ìˆ˜ì§‘ (ë³‘ë ¬).

    Returns:
        NewsItem ë¦¬ìŠ¤íŠ¸ (impact_score ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬)
    """
    import httpx

    target_feeds = feeds or RSS_FEEDS
    all_items: list[NewsItem] = []

    async with httpx.AsyncClient(timeout=10, follow_redirects=True) as client:
        async def _fetch_one(feed: dict) -> list[NewsItem]:
            try:
                resp = await client.get(
                    feed["url"],
                    headers={"User-Agent": "K-Quant/6.0 NewsBot"},
                )
                if resp.status_code == 200:
                    return _parse_rss(resp.text, feed)[:max_per_feed]
            except Exception as e:
                logger.debug("RSS fetch error %s: %s", feed["name"], e)
            return []

        results = await asyncio.gather(
            *[_fetch_one(f) for f in target_feeds],
            return_exceptions=True,
        )
        for result in results:
            if isinstance(result, list):
                all_items.extend(result)

    # impact_score ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    all_items.sort(key=lambda x: (-x.impact_score, x.published), reverse=False)
    return all_items


def filter_urgent_news(items: list[NewsItem]) -> list[NewsItem]:
    """ê¸´ê¸‰ ë‰´ìŠ¤ë§Œ í•„í„° (impact_score >= 8)."""
    return [item for item in items if item.is_urgent]


def format_news_for_context(items: list[NewsItem], max_items: int = 8) -> str:
    """AI ì»¨í…ìŠ¤íŠ¸ìš© ë‰´ìŠ¤ í¬ë§·.

    ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì£¼ì…í•  ê°„ê²°í•œ í˜•ì‹.
    """
    if not items:
        return "ê¸€ë¡œë²Œ ì´ìŠˆ ì—†ìŒ"

    lines = []
    seen_titles = set()
    for item in items[:max_items]:
        # ì¤‘ë³µ ì œê±° (ë¹„ìŠ·í•œ í—¤ë“œë¼ì¸)
        title_key = item.title[:20]
        if title_key in seen_titles:
            continue
        seen_titles.add(title_key)

        urgency = "ğŸš¨" if item.is_urgent else "ğŸ“°"
        impact = f"[ì˜í–¥:{item.impact_score}/10]" if item.impact_score > 0 else ""
        lines.append(f"{urgency} [{item.source}] {item.title} {impact}")

    return "\n".join(lines) if lines else "ê¸€ë¡œë²Œ ì´ìŠˆ ì—†ìŒ"


def format_news_for_telegram(items: list[NewsItem], max_items: int = 10) -> str:
    """í…”ë ˆê·¸ë¨ ì•Œë¦¼ìš© ë‰´ìŠ¤ í¬ë§·."""
    if not items:
        return ""

    now = datetime.now(KST)
    lines = [
        f"ğŸ“° ê¸€ë¡œë²Œ ë‰´ìŠ¤ ë¸Œë¦¬í•‘ ({now.strftime('%H:%M')} KST)",
        f"{'â”' * 22}",
    ]

    urgent = [i for i in items if i.is_urgent]
    normal = [i for i in items if not i.is_urgent]

    if urgent:
        lines.append("\nğŸš¨ ê¸´ê¸‰ ì´ìŠˆ")
        for item in urgent[:5]:
            lines.append(f"  {item.title}")
            lines.append(f"  â€” {item.source}")

    if normal:
        lines.append("\nğŸ“° ì£¼ìš” ë‰´ìŠ¤")
        remaining = max_items - len(urgent[:5])
        for item in normal[:remaining]:
            lines.append(f"  {item.title}")
            lines.append(f"  â€” {item.source}")

    return "\n".join(lines)


def format_urgent_alert(items: list[NewsItem]) -> str:
    """ê¸´ê¸‰ ì´ë²¤íŠ¸ í…”ë ˆê·¸ë¨ ì•Œë¦¼ í¬ë§·."""
    if not items:
        return ""

    now = datetime.now(KST)
    lines = [
        f"ğŸš¨ ê¸´ê¸‰ ê¸€ë¡œë²Œ ì´ë²¤íŠ¸ ({now.strftime('%H:%M')} KST)",
        f"{'â”' * 22}",
    ]
    for item in items[:3]:
        impact_bar = "ğŸ”´" * min(item.impact_score // 2, 5)
        lines.append(f"\n{impact_bar} {item.title}")
        lines.append(f"  ì¶œì²˜: {item.source}")
        lines.append(f"  ì˜í–¥ë„: {item.impact_score}/10")

    lines.append("\nâš ï¸ í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ìŠ¤í¬ ì ê²€ì„ ê¶Œì¥í•©ë‹ˆë‹¤")
    return "\n".join(lines)


# â”€â”€ ìœ„ê¸° ê°ì§€ ì—”ì§„ (ë§¤í¬ë¡œ ì„ í–‰ì§€í‘œ ê¸°ë°˜) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class CrisisSignal:
    """ìœ„ê¸° ê°ì§€ ê²°ê³¼."""
    is_crisis: bool = False
    severity: int = 0  # 0=ì •ìƒ, 1=ì£¼ì˜, 2=ê²½ê³„, 3=ìœ„ê¸°
    label: str = "ì •ìƒ"
    triggers: list[str] = field(default_factory=list)
    recommended_interval: int = 1800  # ë‰´ìŠ¤ ìˆ˜ì§‘ ê°„ê²© (ì´ˆ)


# ê¸°ì¤€ì¹˜: (ì„ê³„ê°’, ì ìˆ˜, ì„¤ëª…)
_CRISIS_THRESHOLDS = {
    "vix_high": (30.0, 3, "VIX 30+ (ê³µí¬)"),
    "vix_spike": (25.0, 2, "VIX 25+ (ê²½ê³„)"),
    "vix_change": (10.0, 2, "VIX ì¼ì¼ ë³€ë™ 10%+"),
    "btc_crash": (-5.0, 2, "BTC ì¼ì¼ -5% ì´ìƒ í•˜ë½"),
    "btc_plunge": (-10.0, 3, "BTC ì¼ì¼ -10% ê¸‰ë½"),
    "gold_surge": (3.0, 2, "ê¸ˆ ì¼ì¼ +3% ê¸‰ë“± (ì•ˆì „ìì‚° ì„ í˜¸)"),
    "spx_crash": (-2.0, 2, "S&P500 -2% ì´ìƒ í•˜ë½"),
    "spx_plunge": (-4.0, 3, "S&P500 -4% ê¸‰ë½"),
    "krw_spike": (2.0, 2, "ì›/ë‹¬ëŸ¬ +2% ê¸‰ë“± (ì›í™” ê¸‰ë½)"),
    "fear_extreme": (20.0, 2, "ê³µí¬íƒìš•ì§€ìˆ˜ ê·¹ë„ê³µí¬ (<20)"),
}


def detect_crisis_from_macro(macro_snapshot) -> CrisisSignal:
    """ë§¤í¬ë¡œ ì„ í–‰ì§€í‘œ ê¸°ë°˜ ìœ„ê¸° ê°ì§€.

    VIX, BTC, ê¸ˆ, S&P500, í™˜ìœ¨, ê³µí¬íƒìš•ì§€ìˆ˜ë¥¼ ì¢…í•©í•˜ì—¬
    ìœ„ê¸° ìˆ˜ì¤€ íŒë‹¨ + ë‰´ìŠ¤ ìˆ˜ì§‘ ì£¼ê¸° ê²°ì •.

    Args:
        macro_snapshot: MacroSnapshot ì¸ìŠ¤í„´ìŠ¤ ë˜ëŠ” dict.
    """
    signal = CrisisSignal()
    score = 0

    # ì†ì„± ì ‘ê·¼ (MacroSnapshot or dict í˜¸í™˜)
    def _get(key: str, default: float = 0.0) -> float:
        if isinstance(macro_snapshot, dict):
            return macro_snapshot.get(key, default)
        return getattr(macro_snapshot, key, default)

    vix = _get("vix", 15.0)
    vix_chg = _get("vix_change_pct", 0.0)
    btc_chg = _get("btc_change_pct", 0.0)
    gold_chg = _get("gold_change_pct", 0.0)
    spx_chg = _get("spx_change_pct", 0.0)
    krw_chg = _get("usdkrw_change_pct", 0.0)
    fear_greed = _get("fear_greed_score", 50.0)

    # VIX ìˆ˜ì¤€
    if vix >= 30:
        score += 3
        signal.triggers.append(f"VIX {vix:.1f} (ê³µí¬)")
    elif vix >= 25:
        score += 2
        signal.triggers.append(f"VIX {vix:.1f} (ê²½ê³„)")

    # VIX ê¸‰ë³€
    if abs(vix_chg) >= 10:
        score += 2
        signal.triggers.append(f"VIX ë³€ë™ {vix_chg:+.1f}%")

    # BTC (ë¦¬ìŠ¤í¬ ìì‚° ì„ í–‰)
    if btc_chg <= -10:
        score += 3
        signal.triggers.append(f"BTC {btc_chg:+.1f}% ê¸‰ë½")
    elif btc_chg <= -5:
        score += 2
        signal.triggers.append(f"BTC {btc_chg:+.1f}% í•˜ë½")

    # ê¸ˆ (ì•ˆì „ìì‚° ê¸‰ë“± = ìœ„ê¸° ì‹ í˜¸)
    if gold_chg >= 3:
        score += 2
        signal.triggers.append(f"ê¸ˆ {gold_chg:+.1f}% ê¸‰ë“±")

    # S&P500
    if spx_chg <= -4:
        score += 3
        signal.triggers.append(f"S&P500 {spx_chg:+.2f}% ê¸‰ë½")
    elif spx_chg <= -2:
        score += 2
        signal.triggers.append(f"S&P500 {spx_chg:+.2f}% í•˜ë½")

    # í™˜ìœ¨ (ì›í™” ê¸‰ë½ = ì™¸ì ì´íƒˆ)
    if krw_chg >= 2:
        score += 2
        signal.triggers.append(f"ì›/ë‹¬ëŸ¬ {krw_chg:+.1f}% ê¸‰ë“±")

    # ê³µí¬íƒìš•ì§€ìˆ˜
    if fear_greed <= 20:
        score += 2
        signal.triggers.append(f"ê³µí¬íƒìš• {fear_greed:.0f} (ê·¹ë„ê³µí¬)")

    # ì¢…í•© íŒë‹¨
    if score >= 6:
        signal.is_crisis = True
        signal.severity = 3
        signal.label = "ìœ„ê¸°"
        signal.recommended_interval = 300  # 5ë¶„
    elif score >= 4:
        signal.is_crisis = True
        signal.severity = 2
        signal.label = "ê²½ê³„"
        signal.recommended_interval = 600  # 10ë¶„
    elif score >= 2:
        signal.severity = 1
        signal.label = "ì£¼ì˜"
        signal.recommended_interval = 900  # 15ë¶„
    else:
        signal.severity = 0
        signal.label = "ì •ìƒ"
        signal.recommended_interval = 1800  # 30ë¶„

    return signal


def format_crisis_alert(signal: CrisisSignal) -> str:
    """ìœ„ê¸° ê°ì§€ í…”ë ˆê·¸ë¨ ì•Œë¦¼ í¬ë§·."""
    if signal.severity < 2:
        return ""

    now = datetime.now(KST)
    severity_emoji = {1: "ğŸŸ¡", 2: "ğŸŸ ", 3: "ğŸ”´"}
    emoji = severity_emoji.get(signal.severity, "âšª")

    lines = [
        f"{emoji} ê¸€ë¡œë²Œ ìœ„ê¸° ê°ì§€ â€” {signal.label}",
        f"{'â”' * 22}",
        f"ì‹œê°„: {now.strftime('%H:%M')} KST",
        "",
    ]
    for trigger in signal.triggers:
        lines.append(f"  âš ï¸ {trigger}")

    lines.append(f"\në‰´ìŠ¤ ê°ì‹œ ì£¼ê¸°: {signal.recommended_interval // 60}ë¶„ìœ¼ë¡œ ê°•í™”")
    if signal.severity >= 3:
        lines.append("\nğŸš¨ í¬íŠ¸í´ë¦¬ì˜¤ ê¸´ê¸‰ ì ê²€ì„ ê¶Œì¥í•©ë‹ˆë‹¤")

    return "\n".join(lines)
