"""ì‹œê·¸ë„ ì •ì œ ì—”ì§„ â€” v5.0-5.

45ê°œ ì‹œê·¸ë„ì„ ìƒê´€ë¶„ì„ìœ¼ë¡œ ì •ì œí•˜ì—¬ 20~25ê°œ ë…ë¦½ ì‹œê·¸ë„ë¡œ ì¶•ì†Œí•œë‹¤.
ë‹¤ì¤‘ ê³µì„ ì„±(multicollinearity)ì„ ì œê±°í•˜ê³ , ì •ë³´ ë¹„ìœ¨ì´ ë†’ì€ ì‹œê·¸ë„ë§Œ ìœ ì§€.

í•µì‹¬ ê¸°ëŠ¥:
  1. SignalCorrelationMatrix â€” ì‹œê·¸ë„ ê°„ ìƒê´€ê³„ìˆ˜ í–‰ë ¬ ê³„ì‚°
  2. SignalPruner â€” ê³ ìƒê´€ ì‹œê·¸ë„ ê·¸ë£¹ì—ì„œ ëŒ€í‘œ ì„ ì • + ì¤‘ë³µ ì œê±°
  3. PurgedKFoldCV â€” Purged K-Fold êµì°¨ê²€ì¦ (ì‹œê³„ì—´ ë°ì´í„° ëˆ„ì¶œ ë°©ì§€)
  4. SignalQualityScore â€” ì‹œê·¸ë„ í’ˆì§ˆ í‰ê°€ (IC, turnover, decay)
"""

from __future__ import annotations

import logging
import math
from dataclasses import dataclass, field
from typing import Any

logger = logging.getLogger(__name__)


# â”€â”€ ì‹œê·¸ë„ ë©”íƒ€ë°ì´í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class SignalMeta:
    """ì‹œê·¸ë„ ë©”íƒ€ ì •ë³´."""
    name: str
    category: str = ""         # "momentum", "value", "sentiment", "technical", etc.
    source_module: str = ""    # ì†ŒìŠ¤ ëª¨ë“ˆ ê²½ë¡œ
    lookback_days: int = 0     # ë£©ë°± ê¸°ê°„
    update_freq: str = "daily" # "realtime", "daily", "weekly"


@dataclass
class SignalQuality:
    """ì‹œê·¸ë„ í’ˆì§ˆ í‰ê°€."""
    name: str
    ic: float = 0.0                    # Information Coefficient (ìˆ˜ìµë¥ ê³¼ì˜ ìƒê´€)
    ic_std: float = 0.0                # IC í‘œì¤€í¸ì°¨
    icir: float = 0.0                  # IC Information Ratio (IC/IC_std)
    avg_turnover: float = 0.0          # í‰ê·  íšŒì „ìœ¨
    decay_halflife_days: float = 0.0   # ì‹œê·¸ë„ ë°˜ê°ê¸° (ì¼)
    hit_rate: float = 0.0              # ë°©í–¥ ì ì¤‘ë¥ 
    quality_score: float = 0.0         # ì¢…í•© í’ˆì§ˆ ì ìˆ˜ (0~100)
    is_selected: bool = True           # ì •ì œ í›„ ì„ íƒ ì—¬ë¶€


@dataclass
class CorrelationCluster:
    """ê³ ìƒê´€ ì‹œê·¸ë„ í´ëŸ¬ìŠ¤í„°."""
    cluster_id: int
    signals: list[str]
    avg_correlation: float
    representative: str        # ëŒ€í‘œ ì‹œê·¸ë„
    removed: list[str]         # ì œê±°ëœ ì‹œê·¸ë„


@dataclass
class RefineryReport:
    """ì‹œê·¸ë„ ì •ì œ ê²°ê³¼."""
    timestamp: str = ""
    total_signals: int = 0
    selected_signals: int = 0
    removed_signals: int = 0
    clusters: list[CorrelationCluster] = field(default_factory=list)
    quality_scores: list[SignalQuality] = field(default_factory=list)
    correlation_threshold: float = 0.0
    recommendations: list[str] = field(default_factory=list)


# â”€â”€ ìƒê´€ í–‰ë ¬ ê³„ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class SignalCorrelationMatrix:
    """ì‹œê·¸ë„ ê°„ ìƒê´€ê³„ìˆ˜ í–‰ë ¬ ê³„ì‚°.

    numpy ì—†ì´ ìˆœìˆ˜ Pythonìœ¼ë¡œ êµ¬í˜„.
    """

    @staticmethod
    def compute(
        signals: dict[str, list[float]],
    ) -> dict[tuple[str, str], float]:
        """ì‹œê·¸ë„ ê°„ í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ë¥¼ ê³„ì‚°í•œë‹¤.

        Args:
            signals: {ì‹œê·¸ë„ëª…: ê°’ ë¦¬ìŠ¤íŠ¸} ë”•ì…”ë„ˆë¦¬. ëª¨ë“  ë¦¬ìŠ¤íŠ¸ ê¸¸ì´ ë™ì¼.

        Returns:
            {(ì‹œê·¸ë„A, ì‹œê·¸ë„B): ìƒê´€ê³„ìˆ˜} ë”•ì…”ë„ˆë¦¬.
        """
        names = sorted(signals.keys())
        corr_map: dict[tuple[str, str], float] = {}

        for i, name_a in enumerate(names):
            vals_a = signals[name_a]
            for j, name_b in enumerate(names):
                if j <= i:
                    continue
                vals_b = signals[name_b]
                r = _pearson(vals_a, vals_b)
                corr_map[(name_a, name_b)] = r
                corr_map[(name_b, name_a)] = r

        return corr_map

    @staticmethod
    def find_high_correlation_pairs(
        corr_map: dict[tuple[str, str], float],
        threshold: float = 0.7,
    ) -> list[tuple[str, str, float]]:
        """ì„ê³„ê°’ ì´ìƒ ê³ ìƒê´€ ìŒ ì¶”ì¶œ."""
        seen = set()
        pairs = []
        for (a, b), r in corr_map.items():
            key = (min(a, b), max(a, b))
            if key in seen:
                continue
            seen.add(key)
            if abs(r) >= threshold:
                pairs.append((a, b, r))

        pairs.sort(key=lambda x: abs(x[2]), reverse=True)
        return pairs


# â”€â”€ ì‹œê·¸ë„ í”„ë£¨ë„ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class SignalPruner:
    """ê³ ìƒê´€ ì‹œê·¸ë„ ê·¸ë£¹ì—ì„œ ëŒ€í‘œ ì„ ì • + ì¤‘ë³µ ì œê±°.

    ì•Œê³ ë¦¬ì¦˜:
      1. ìƒê´€ê³„ìˆ˜ í–‰ë ¬ì—ì„œ threshold ì´ìƒ ìŒì„ ì¶”ì¶œ
      2. Union-Findë¡œ í´ëŸ¬ìŠ¤í„° êµ¬ì„±
      3. ê° í´ëŸ¬ìŠ¤í„°ì—ì„œ í’ˆì§ˆ ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ì‹œê·¸ë„ì„ ëŒ€í‘œë¡œ ì„ ì •
      4. ë‚˜ë¨¸ì§€ëŠ” ì œê±° í›„ë³´

    Target: 45ê°œ â†’ 20~25ê°œ
    """

    def __init__(self, correlation_threshold: float = 0.7):
        self.threshold = correlation_threshold

    def prune(
        self,
        signals: dict[str, list[float]],
        quality_map: dict[str, float] | None = None,
        target_count: int | None = None,
    ) -> RefineryReport:
        """ì‹œê·¸ë„ ì •ì œ ì‹¤í–‰.

        Args:
            signals: {ì‹œê·¸ë„ëª…: ê°’ ë¦¬ìŠ¤íŠ¸}.
            quality_map: {ì‹œê·¸ë„ëª…: í’ˆì§ˆ ì ìˆ˜}. Noneì´ë©´ IC ê¸°ë°˜ ìë™ ê³„ì‚°.
            target_count: ëª©í‘œ ì‹œê·¸ë„ ìˆ˜. Noneì´ë©´ ìë™.

        Returns:
            RefineryReport.
        """
        if not signals:
            return RefineryReport()

        names = sorted(signals.keys())
        total = len(names)

        # ìƒê´€ í–‰ë ¬ ê³„ì‚°
        corr_map = SignalCorrelationMatrix.compute(signals)
        high_pairs = SignalCorrelationMatrix.find_high_correlation_pairs(
            corr_map, self.threshold,
        )

        # í’ˆì§ˆ ì ìˆ˜ (ì—†ìœ¼ë©´ ë¶„ì‚° ê¸°ë°˜ ëŒ€ì²´)
        if quality_map is None:
            quality_map = {}
            for name, vals in signals.items():
                quality_map[name] = _signal_variance_score(vals)

        # Union-Findë¡œ í´ëŸ¬ìŠ¤í„° êµ¬ì„±
        parent: dict[str, str] = {n: n for n in names}

        def find(x: str) -> str:
            while parent[x] != x:
                parent[x] = parent[parent[x]]
                x = parent[x]
            return x

        def union(x: str, y: str) -> None:
            rx, ry = find(x), find(y)
            if rx != ry:
                parent[rx] = ry

        for a, b, _ in high_pairs:
            union(a, b)

        # í´ëŸ¬ìŠ¤í„° ìˆ˜ì§‘
        cluster_members: dict[str, list[str]] = {}
        for n in names:
            root = find(n)
            cluster_members.setdefault(root, []).append(n)

        # ê° í´ëŸ¬ìŠ¤í„°ì—ì„œ ëŒ€í‘œ ì„ ì •
        clusters: list[CorrelationCluster] = []
        selected: set[str] = set()
        removed: set[str] = set()

        for idx, (root, members) in enumerate(
            sorted(cluster_members.items(), key=lambda x: -len(x[1]))
        ):
            if len(members) == 1:
                selected.add(members[0])
                continue

            # í’ˆì§ˆ ê¸°ì¤€ ì •ë ¬
            members_sorted = sorted(
                members, key=lambda n: quality_map.get(n, 0), reverse=True,
            )
            representative = members_sorted[0]
            selected.add(representative)
            to_remove = members_sorted[1:]
            removed.update(to_remove)

            # í´ëŸ¬ìŠ¤í„° ë‚´ í‰ê·  ìƒê´€
            pair_corrs = []
            for i, a in enumerate(members):
                for b in members[i + 1:]:
                    key = (a, b) if (a, b) in corr_map else (b, a)
                    if key in corr_map:
                        pair_corrs.append(abs(corr_map[key]))
            avg_corr = sum(pair_corrs) / len(pair_corrs) if pair_corrs else 0

            clusters.append(CorrelationCluster(
                cluster_id=idx,
                signals=members,
                avg_correlation=round(avg_corr, 3),
                representative=representative,
                removed=to_remove,
            ))

        # ëª©í‘œ ìˆ˜ì— ë§ê²Œ ì¶”ê°€ ì œê±°
        if target_count and len(selected) > target_count:
            # í’ˆì§ˆ ë‚®ì€ ìˆœìœ¼ë¡œ ì¶”ê°€ ì œê±°
            selected_list = sorted(
                selected, key=lambda n: quality_map.get(n, 0),
            )
            while len(selected) > target_count and selected_list:
                to_drop = selected_list.pop(0)
                selected.discard(to_drop)
                removed.add(to_drop)

        # í’ˆì§ˆ ì ìˆ˜ ë¦¬ìŠ¤íŠ¸
        quality_scores = []
        for name in names:
            quality_scores.append(SignalQuality(
                name=name,
                quality_score=round(quality_map.get(name, 0), 2),
                is_selected=name in selected,
            ))
        quality_scores.sort(key=lambda q: q.quality_score, reverse=True)

        # ì¶”ì²œ
        recommendations = []
        if len(removed) > 0:
            recommendations.append(
                f"âœ‚ï¸ {total}ê°œ â†’ {len(selected)}ê°œ ì‹œê·¸ë„ ì •ì œ ì™„ë£Œ "
                f"(ìƒê´€ {self.threshold:.1f} ê¸°ì¤€)"
            )
        multi_clusters = [c for c in clusters if len(c.signals) > 2]
        if multi_clusters:
            for c in multi_clusters[:3]:
                recommendations.append(
                    f"ğŸ”— í´ëŸ¬ìŠ¤í„° {c.cluster_id}: {', '.join(c.signals[:3])}... "
                    f"(ìƒê´€ {c.avg_correlation:.2f}) â†’ ëŒ€í‘œ: {c.representative}"
                )

        return RefineryReport(
            total_signals=total,
            selected_signals=len(selected),
            removed_signals=len(removed),
            clusters=clusters,
            quality_scores=quality_scores,
            correlation_threshold=self.threshold,
            recommendations=recommendations,
        )


# â”€â”€ Purged K-Fold CV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class PurgedKFoldCV:
    """Purged K-Fold êµì°¨ê²€ì¦.

    ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ train/test ì‚¬ì´ ë°ì´í„° ëˆ„ì¶œì„ ë°©ì§€.
    test í´ë“œ ì „í›„ purge_gap ë§Œí¼ì˜ ë°ì´í„°ë¥¼ trainì—ì„œ ì œê±°.
    """

    def __init__(self, n_splits: int = 5, purge_gap: int = 5):
        """
        Args:
            n_splits: í´ë“œ ìˆ˜.
            purge_gap: test ì „í›„ ì œê±°í•  í–‰ ìˆ˜.
        """
        self.n_splits = n_splits
        self.purge_gap = purge_gap

    def split(self, n_samples: int) -> list[tuple[list[int], list[int]]]:
        """ì¸ë±ìŠ¤ë¥¼ train/testë¡œ ë¶„í• .

        Args:
            n_samples: ì „ì²´ ë°ì´í„° ìˆ˜.

        Returns:
            [(train_indices, test_indices), ...] ë¦¬ìŠ¤íŠ¸.
        """
        if n_samples < self.n_splits * 3:
            logger.warning(
                "PurgedKFold: ë°ì´í„° ë¶€ì¡± (%d < %d)",
                n_samples, self.n_splits * 3,
            )
            return []

        fold_size = n_samples // self.n_splits
        splits = []

        for i in range(self.n_splits):
            test_start = i * fold_size
            test_end = min((i + 1) * fold_size, n_samples)

            # Purge: test ì „í›„ gap ì œê±°
            purge_start = max(0, test_start - self.purge_gap)
            purge_end = min(n_samples, test_end + self.purge_gap)

            test_idx = list(range(test_start, test_end))
            train_idx = (
                list(range(0, purge_start))
                + list(range(purge_end, n_samples))
            )

            if train_idx and test_idx:
                splits.append((train_idx, test_idx))

        return splits


# â”€â”€ ì‹œê·¸ë„ ì¹´íƒˆë¡œê·¸ (K-Quant í˜„ì¬ ì‹œê·¸ë„ ë§µ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SIGNAL_CATALOG: list[SignalMeta] = [
    # Technical
    SignalMeta("rsi_14", "technical", "features.technical"),
    SignalMeta("rsi_7", "technical", "features.technical"),
    SignalMeta("macd_histogram", "technical", "features.technical"),
    SignalMeta("macd_signal_cross", "technical", "features.technical"),
    SignalMeta("bb_position", "technical", "features.technical"),
    SignalMeta("bb_width", "technical", "features.technical"),
    SignalMeta("stochastic_k", "technical", "features.technical"),
    SignalMeta("stochastic_d", "technical", "features.technical"),
    SignalMeta("obv_trend", "technical", "features.technical"),
    SignalMeta("atr_pct", "technical", "features.technical"),
    SignalMeta("adx", "technical", "features.technical"),
    SignalMeta("cci", "technical", "features.technical"),
    SignalMeta("williams_r", "technical", "features.technical"),
    SignalMeta("ichimoku_signal", "technical", "features.technical"),
    SignalMeta("volume_ma_ratio", "technical", "features.technical"),
    # Momentum
    SignalMeta("momentum_1w", "momentum", "signal.scoring"),
    SignalMeta("momentum_1m", "momentum", "signal.scoring"),
    SignalMeta("momentum_3m", "momentum", "signal.scoring"),
    SignalMeta("roc_5d", "momentum", "features.technical"),
    SignalMeta("roc_20d", "momentum", "features.technical"),
    SignalMeta("volatility_breakout", "momentum", "signal.volatility_breakout"),
    SignalMeta("gap_signal", "momentum", "signal.gap_trader"),
    SignalMeta("surge_score", "momentum", "signal.surge_detector"),
    # Value / Fundamental
    SignalMeta("per_relative", "value", "signal.factor_scoring"),
    SignalMeta("pbr_relative", "value", "signal.factor_scoring"),
    SignalMeta("roe_rank", "value", "signal.factor_scoring"),
    SignalMeta("dividend_yield", "value", "signal.factor_scoring"),
    SignalMeta("earnings_surprise", "value", "signal.earnings_tracker"),
    SignalMeta("financial_health", "value", "signal.financial_analyzer"),
    # Sentiment / Flow
    SignalMeta("foreign_net_flow", "flow", "signal.foreign_predictor"),
    SignalMeta("institutional_flow", "flow", "signal.institutional_tracker"),
    SignalMeta("short_interest", "flow", "signal.short_selling"),
    SignalMeta("margin_balance", "flow", "signal.margin_balance"),
    SignalMeta("program_trade", "flow", "signal.contrarian_signal"),
    SignalMeta("stealth_accumulation", "flow", "signal.stealth_accumulation"),
    SignalMeta("news_sentiment", "sentiment", "ml.sentiment"),
    SignalMeta("market_psychology", "sentiment", "signal.market_psychology"),
    # Macro / Regime
    SignalMeta("vix_level", "macro", "signal.market_regime"),
    SignalMeta("market_regime", "macro", "signal.market_regime"),
    SignalMeta("sector_momentum", "macro", "core.sector_rotation"),
    SignalMeta("fx_signal", "macro", "signal.fx_strategy"),
    # Strategy-specific
    SignalMeta("swing_entry", "strategy", "signal.swing_trader"),
    SignalMeta("pair_spread", "strategy", "signal.pair_signal"),
    SignalMeta("tenbagger_score", "strategy", "signal.tenbagger_hunter"),
    SignalMeta("contrarian_composite", "strategy", "signal.contrarian_signal"),
    SignalMeta("consensus_divergence", "strategy", "signal.consensus_tracker"),
]


def get_signal_catalog() -> list[SignalMeta]:
    """í˜„ì¬ ì‹œê·¸ë„ ì¹´íƒˆë¡œê·¸ ë°˜í™˜."""
    return SIGNAL_CATALOG.copy()


# â”€â”€ í—¬í¼ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _pearson(x: list[float], y: list[float]) -> float:
    """í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ (ìˆœìˆ˜ Python)."""
    n = min(len(x), len(y))
    if n < 3:
        return 0.0

    x, y = x[:n], y[:n]
    mx = sum(x) / n
    my = sum(y) / n

    cov = sum((xi - mx) * (yi - my) for xi, yi in zip(x, y))
    sx = math.sqrt(sum((xi - mx) ** 2 for xi in x))
    sy = math.sqrt(sum((yi - my) ** 2 for yi in y))

    if sx == 0 or sy == 0:
        return 0.0

    return cov / (sx * sy)


def _signal_variance_score(values: list[float]) -> float:
    """ë¶„ì‚° ê¸°ë°˜ ì‹œê·¸ë„ í’ˆì§ˆ ëŒ€ì²´ ì ìˆ˜.

    ê°’ì˜ ë³€ë™ì´ í´ìˆ˜ë¡ ì •ë³´ëŸ‰ì´ ë†’ë‹¤ê³  ê°„ì£¼.
    """
    if not values or len(values) < 2:
        return 0.0

    n = len(values)
    mean = sum(values) / n
    var = sum((v - mean) ** 2 for v in values) / (n - 1)

    # ì •ê·œí™”: í‘œì¤€í¸ì°¨ë¥¼ 0~100 ìŠ¤ì¼€ì¼
    std = math.sqrt(var)
    # ë¹„ì œë¡œ ë¹„ìœ¨ë„ ë°˜ì˜ (ìƒìˆ˜ ì‹œê·¸ë„ íŒ¨ë„í‹°)
    nonzero_ratio = sum(1 for v in values if v != 0) / n

    return min(100.0, std * 10 * nonzero_ratio)


# â”€â”€ í…”ë ˆê·¸ë¨ í¬ë§· â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def format_refinery_report(report: RefineryReport) -> str:
    """ì •ì œ ê²°ê³¼ë¥¼ í…”ë ˆê·¸ë¨ í¬ë§·."""
    if report.total_signals == 0:
        return "ğŸ”¬ ì‹œê·¸ë„ ì •ì œ: ë°ì´í„° ì—†ìŒ"

    lines = [
        "ğŸ”¬ ì‹œê·¸ë„ ì •ì œ ê²°ê³¼",
        "â”" * 25,
        f"ì „ì²´: {report.total_signals}ê°œ â†’ ì„ íƒ: {report.selected_signals}ê°œ",
        f"ì œê±°: {report.removed_signals}ê°œ (ìƒê´€ {report.correlation_threshold:.1f} ê¸°ì¤€)",
        "",
    ]

    # í´ëŸ¬ìŠ¤í„°
    multi = [c for c in report.clusters if len(c.signals) > 1]
    if multi:
        lines.append(f"ğŸ”— í´ëŸ¬ìŠ¤í„°: {len(multi)}ê°œ")
        for c in multi[:5]:
            lines.append(
                f"  [{c.cluster_id}] {', '.join(c.signals[:3])}"
                f"{'...' if len(c.signals) > 3 else ''}"
                f" â†’ ëŒ€í‘œ: {c.representative}"
            )
        lines.append("")

    # ìƒìœ„ í’ˆì§ˆ ì‹œê·¸ë„
    selected = [q for q in report.quality_scores if q.is_selected][:10]
    if selected:
        lines.append("â­ ìƒìœ„ ì‹œê·¸ë„:")
        for q in selected:
            lines.append(f"  {q.name}: {q.quality_score:.1f}ì ")

    # ì¶”ì²œ
    if report.recommendations:
        lines.extend(["", "â”" * 25])
        for rec in report.recommendations[:3]:
            lines.append(f"  {rec}")

    return "\n".join(lines)
